{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/ouladsayadyounes/WildFires/raw/master/WildFires_DataSet.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['CLASS'] = label_encoder.fit_transform(df['CLASS'])\n",
    "df['LST'] *= 0.02\n",
    "df['LST'] -= 273.15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       NDVI   LST  BURNED_AREA\nCLASS                         \n0       386   386          386\n1      1327  1327         1327",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDVI</th>\n      <th>LST</th>\n      <th>BURNED_AREA</th>\n    </tr>\n    <tr>\n      <th>CLASS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>386</td>\n      <td>386</td>\n      <td>386</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1327</td>\n      <td>1327</td>\n      <td>1327</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('CLASS').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X = df.drop('CLASS', axis=1)\n",
    "y = df['CLASS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.29      0.39       112\n",
      "           1       0.83      0.95      0.88       402\n",
      "\n",
      "    accuracy                           0.80       514\n",
      "   macro avg       0.71      0.62      0.63       514\n",
      "weighted avg       0.78      0.80      0.77       514\n",
      "\n",
      "0.8015564202334631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(21,21,21), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.33      0.42       112\n",
      "           1       0.83      0.93      0.88       402\n",
      "\n",
      "    accuracy                           0.80       514\n",
      "   macro avg       0.71      0.63      0.65       514\n",
      "weighted avg       0.78      0.80      0.78       514\n",
      "\n",
      "0.8015564202334631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11       112\n",
      "           1       0.79      0.98      0.88       402\n",
      "\n",
      "    accuracy                           0.78       514\n",
      "   macro avg       0.65      0.52      0.49       514\n",
      "weighted avg       0.73      0.78      0.71       514\n",
      "\n",
      "0.7821011673151751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50       112\n",
      "           1       0.86      0.87      0.87       402\n",
      "\n",
      "    accuracy                           0.79       514\n",
      "   macro avg       0.69      0.68      0.68       514\n",
      "weighted avg       0.78      0.79      0.79       514\n",
      "\n",
      "0.7879377431906615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.46      0.57       112\n",
      "           1       0.86      0.95      0.91       402\n",
      "\n",
      "    accuracy                           0.85       514\n",
      "   macro avg       0.80      0.71      0.74       514\n",
      "weighted avg       0.84      0.85      0.83       514\n",
      "\n",
      "0.8463035019455253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.26      0.37       112\n",
      "           1       0.82      0.96      0.89       402\n",
      "\n",
      "    accuracy                           0.81       514\n",
      "   macro avg       0.74      0.61      0.63       514\n",
      "weighted avg       0.79      0.81      0.78       514\n",
      "\n",
      "0.8093385214007782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = abc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.29      0.41       112\n",
      "           1       0.83      0.96      0.89       402\n",
      "\n",
      "    accuracy                           0.81       514\n",
      "   macro avg       0.74      0.63      0.65       514\n",
      "weighted avg       0.79      0.81      0.78       514\n",
      "\n",
      "0.8132295719844358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.43      0.52       112\n",
      "           1       0.86      0.94      0.90       402\n",
      "\n",
      "    accuracy                           0.83       514\n",
      "   macro avg       0.77      0.69      0.71       514\n",
      "weighted avg       0.82      0.83      0.82       514\n",
      "\n",
      "0.830739299610895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = etc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.07      0.12       112\n",
      "           1       0.79      0.97      0.87       402\n",
      "\n",
      "    accuracy                           0.77       514\n",
      "   macro avg       0.58      0.52      0.49       514\n",
      "weighted avg       0.70      0.77      0.70       514\n",
      "\n",
      "0.7704280155642024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.07      0.12       112\n",
      "           1       0.79      0.97      0.87       402\n",
      "\n",
      "    accuracy                           0.77       514\n",
      "   macro avg       0.59      0.52      0.50       514\n",
      "weighted avg       0.70      0.77      0.71       514\n",
      "\n",
      "0.77431906614786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.06      0.10       112\n",
      "           1       0.79      0.96      0.87       402\n",
      "\n",
      "    accuracy                           0.77       514\n",
      "   macro avg       0.55      0.51      0.49       514\n",
      "weighted avg       0.68      0.77      0.70       514\n",
      "\n",
      "0.7665369649805448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.11      0.15       112\n",
      "           1       0.79      0.92      0.85       402\n",
      "\n",
      "    accuracy                           0.74       514\n",
      "   macro avg       0.52      0.51      0.50       514\n",
      "weighted avg       0.67      0.74      0.69       514\n",
      "\n",
      "0.7392996108949417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03       112\n",
      "           1       0.78      1.00      0.88       402\n",
      "\n",
      "    accuracy                           0.78       514\n",
      "   macro avg       0.64      0.51      0.46       514\n",
      "weighted avg       0.72      0.78      0.69       514\n",
      "\n",
      "0.7821011673151751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.73      0.44       112\n",
      "           1       0.88      0.55      0.67       402\n",
      "\n",
      "    accuracy                           0.59       514\n",
      "   macro avg       0.60      0.64      0.56       514\n",
      "weighted avg       0.76      0.59      0.62       514\n",
      "\n",
      "0.5875486381322957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "pct = Perceptron(random_state=42)\n",
    "pct.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pct.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.07      0.12       112\n",
      "           1       0.79      0.96      0.87       402\n",
      "\n",
      "    accuracy                           0.77       514\n",
      "   macro avg       0.57      0.52      0.49       514\n",
      "weighted avg       0.69      0.77      0.70       514\n",
      "\n",
      "0.7684824902723736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pac = PassiveAggressiveClassifier(random_state=42)\n",
    "pac.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pac.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.04      0.08       112\n",
      "           1       0.79      0.98      0.87       402\n",
      "\n",
      "    accuracy                           0.78       514\n",
      "   macro avg       0.60      0.51      0.48       514\n",
      "weighted avg       0.71      0.78      0.70       514\n",
      "\n",
      "0.7782101167315175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rc = RidgeClassifier(random_state=42)\n",
    "rc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.04      0.08       112\n",
      "           1       0.79      0.98      0.87       402\n",
      "\n",
      "    accuracy                           0.78       514\n",
      "   macro avg       0.60      0.51      0.48       514\n",
      "weighted avg       0.71      0.78      0.70       514\n",
      "\n",
      "0.7782101167315175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "rccv = RidgeClassifierCV()\n",
    "rccv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rccv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11       112\n",
      "           1       0.79      0.98      0.88       402\n",
      "\n",
      "    accuracy                           0.78       514\n",
      "   macro avg       0.65      0.52      0.49       514\n",
      "weighted avg       0.73      0.78      0.71       514\n",
      "\n",
      "0.7821011673151751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lrcv = LogisticRegressionCV(random_state=42)\n",
    "lrcv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lrcv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}